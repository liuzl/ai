version: "1.0"

# Model routing configuration
# Each model is mapped to a specific backend provider
models:
  # OpenAI models
  - name: "gpt-5.1"
    provider: "openai"
    description: "GPT-5.1"

  - name: "gpt-5.1-codex"
    provider: "openai"
    description: "GPT-5.1 Codex"

  - name: "gpt-5.1-codex-mini"
    provider: "openai"
    description: "GPT-5.1 Codex Mini"

  # Gemini models
  - name: "gemini-3-pro-preview"
    provider: "gemini"
    description: "Gemini 3 Pro Preview"

  - name: "gemini-2.5-pro"
    provider: "gemini"
    description: "Gemini 2.5 Pro"

  - name: "gemini-2.5-flash"
    provider: "gemini"
    description: "Gemini 2.5 Flash"

  - name: "gemini-2.5-flash-lite"
    provider: "gemini"
    description: "Gemini 2.5 Flash Lite"

  - name: "gemini-2.0-flash"
    provider: "gemini"
    description: "Gemini 2.0 Flash"

  # Anthropic models (via BigModel Anthropic-compatible API)
  - name: "glm-4.6"
    provider: "anthropic"
    description: "GLM-4.6 via Anthropic API"

# Optional: fallback provider for unknown models
# default_provider: "openai"

# Optional: custom timeout (default: 5m)
# timeout: "5m"
